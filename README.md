# TP 5 â€“ SIA Â· Deep Learning  
*Autoencoders, Denoising AE y Variational AE*

> **Sistemas de Inteligencia Artificial**  
> ITBA â€“ 2025  

[ğŸ“‘ Enunciado oficial](docs/sia-tp5.pdf)

---

## IntroducciÃ³n

Este TP explora tres variantes de autoencoders sobre distintos datasets:

* **AE bÃ¡sico** â€“ aprende los 32 caracteres 5 Ã— 7 de `font.h`  
* **Denoising AE** â€“ quita ruido binario de los mismos caracteres  
* **VAE** â€“ genera emojis (OpenMoji) y disentangled sprites (dSprites)

El cÃ³digo es *NumPy-only* y corre en CPU en minutos.

---

## âš™ï¸ InstalaciÃ³n rÃ¡pida

1. Clonar el repositorio  
   ```git clone https://github.com/tu-usuario/sia-tp5.git```
2. Crear y activar entorno virtual  
   ```python -m venv venv && source venv/bin/activate```
3. Instalar dependencias  
   ```pip install -r requirements.txt```

---

## â–¶ï¸ EjecuciÃ³n

### Ejercicio 1a â€” Autoencoder bÃ¡sico (font.h)

Runnerâ€ƒ`src/runner_autoencoder.py`  
Flags principales  
â€¢ `config_path` â€“ JSON con arquitectura  
â€¢ `font_path`  â€“ ruta a font.h  

Ejemplo mÃ­nimo  
```python src/runner_autoencoder.py configs/ae.json data/font.h```

Genera  
checkpoints/ae_weights.npz   Â·  checkpoints/loss_history.npy

---

### Ejercicio 1b â€” Denoising Autoencoder

Runnerâ€ƒ`src/runner_dae.py`  
Flags extra  
â€¢ `noise_level` (en el JSON) â€“ prob. de voltear cada bit  

Ejemplo con 10 % de ruido  
```python src/runner_dae.py configs/dae.json data/font.h```

Salida adicional: mÃ©trica *bits error* por carÃ¡cter.

---

### Ejercicio 2 â€” Variational AE

Runner  `src/runner_vae.py`  
**Flags clave**  
â€¢ `--dataset`â€ƒfaces_only | emoji_full | dsprites | faces_lfw  
â€¢ `--img_size`â€ƒ28 / 32 / 64 (se ajusta solo para dsprites / ffhq / lfw)  
â€¢ `--beta_final`â€ƒvalor final de Î²  
â€¢ `--kl_ramp_epochs`â€ƒÃ©pocas para annealing 0 â†’ Î²  
â€¢ `--max_emojis`â€ƒmÃ¡x. de imÃ¡genes a usar  
â€¢ `--refresh_dataset`â€ƒre-descarga forzada (OpenMoji)

**Comandos sugeridos**

| Dataset | Comando | Comentario |
|---------|---------|------------|
| Caras amarillas (197Ã—32 px) | ```python src/runner_vae.py configs/vae_optimized.json --dataset faces_only``` | demo rÃ¡pida |
| OpenMoji completo (â‰ˆ 4 200) | ```python src/runner_vae.py configs/vae_optimized.json --dataset emoji_full --max_emojis 2000``` | mÃ¡s diversidad |
| dSprites 64Ã—64 | ```python src/runner_vae.py configs/vae_optimized.json --dataset dsprites --beta_final 4 --kl_ramp_epochs 100``` | prueba disentanglement |
| LFW deepfunneled (8 000) | ```python src/runner_vae.py configs/vae_optimized.json --dataset faces_lfw --max_emojis 8000 --img_size 64``` | descarga via TF-Datasets |

Cada ejecuciÃ³n crea  
`checkpoints/<dataset>_img<size>_beta<Î²>_<timestamp>/`  
â€ƒÂ· vae_weights.npzâ€ƒÂ· loss_history.npyâ€ƒÂ· vae_generated.png  

AdemÃ¡s se guarda un *sample* del dataset en  
`data/sample_<dataset>.png`

## ğŸ“ Estructura de carpetas

src/              Â· implementaciÃ³n AE / VAE / trainer  
configs/          Â· JSON de hiper-parÃ¡metros  
data/             Â· datasets y samples de referencia  
checkpoints/      Â· pesos + salidas organizadas por experimento  
docs/             Â· enunciado y apuntes Ãºtiles  

---

## ğŸ“Š AnÃ¡lisis de resultados  *(pendiente)*

Se agregarÃ¡n:  
â€¢ grÃ¡ficas de convergencia,  
â€¢ proyecciÃ³n 2-D del espacio latente (AE) y  
â€¢ interpolaciones en el VAE con distintas Î².