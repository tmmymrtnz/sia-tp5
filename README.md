# TP 5 ‚Äì SIA ¬∑ Deep Learning  
*Autoencoders, Denoising AE y Variational AE*

> **Sistemas de Inteligencia Artificial**  
> ITBA ‚Äì 2025  

[üìë Enunciado oficial](docs/sia-tp5.pdf)

---

## Introducci√≥n

Este TP explora tres variantes de autoencoders sobre distintos datasets:

* **AE b√°sico** ‚Äì aprende los 32 caracteres 5 √ó 7 de `font.h`  
* **Denoising AE** ‚Äì quita ruido binario de los mismos caracteres  
* **VAE** ‚Äì genera emojis (OpenMoji) y disentangled sprites (dSprites)

El c√≥digo es *NumPy-only* y corre en CPU en minutos.

---

## ‚öôÔ∏è Instalaci√≥n r√°pida

1. Clonar el repositorio  
   ```git clone https://github.com/tu-usuario/sia-tp5.git```
2. Crear y activar entorno virtual  
   ```python -m venv venv && source venv/bin/activate```
3. Instalar dependencias  
   ```pip install -r requirements.txt```

---

## ‚ñ∂Ô∏è Ejecuci√≥n

### Ejercicio 1a ‚Äî Autoencoder b√°sico (font.h)
1. Para encontrar la arquitectura √≥ptima, se debe correr:
   ```bash
   python src/ex1/part_a/ej_b.py configs/ex1/config_a_1.json
   ```
   Donde el archivo de configuraci√≥n contiene distintos experimentos y el directorio de font.h
   En el directorio `/experimentos` se guardar√° el gr√°fico de p√©rdida por √©poca y un archivo json con los resultados finales de cada experimento.

2. Para graficar el espacio latente, se debe correr:
   ```bash 
   python src/ex1/part_a/ej_c.py
   ```
   Tomar√° directamente el archivo font.h y la configuraci√≥n `configs/ex1/optimal.json` donde se encuentran los detalles de la arquitectura √≥ptima hallada en el item anterior.
   Genera un gr√°fico del espacio latente 2D con los caracteres proyectados sobre el punto (z) que los codifica.

3. Para generar nuevas letras que no pertenecen al conjunto de entrenamiento, se debe correr:
   ```bash
   python src/ex1/part_a/ej_d.py
   ```
   Entrena al autoencoder con las configuraciones √≥ptimas de `configs/ex1/optimal.json`, luego se realizan tres gr√°ficos: primero se divide el espacio latente en 25 bloques (5x5), cada uno con un punto central (x,y). Se usa este punto (x,y) como entrada del decodificador, generando un caracter para este punto. Se genera un gr√°fico con los 25 caracteres generados. Se repite el proceso para 10x10 y 20x20.

---

### Ejercicio 1b ‚Äî Denoising Autoencoder
Para distorsionar las entradas y estudiar la capacidad del Autoencoder de eliminar el ruido, se debe correr:
```bash
python src/analisis_dae.py configs/ex1/optimal.json data/font.h
```
En la configuraci√≥n se especifica la arquitectura √≥ptima y el nivel de ruido para la prueba.
Se har√°n 5 ejecuciones de esta prueba de denoising.
Se generar√°n tres archivos en `/checkpoints`
* `dae_loss_avg_plot.png` con la p√©rdida promedio a lo largo de las √©pocas en las 5 ejecuciones
* `ejemplo_mejor.png` y `ejemplo_peor.png` con una visualizaci√≥n de la entrada con ruido, la reconstrucci√≥n del AE y la entrada original para el caracter con menos bits de error en promedio, y el caracter con m√°s bits de error en promedio.

---

### Ejercicio 2 ‚Äî Variational AE

Runner‚ÄÉ`src/runner_vae.py`  
Flags clave  
‚Ä¢ `--dataset`        faces_only | emoji_full | dsprites  
‚Ä¢ `--img_size`       28/32/64 (seg√∫n dataset)  
‚Ä¢ `--beta_final`     valor final de Œ≤  
‚Ä¢ `--kl_ramp_epochs` √©pocas para annealing 0 ‚Üí Œ≤  

Comandos sugeridos  

| Dataset | Comando | Comentario |
|---------|---------|------------|
| Caras amarillas (197) | ```python src/runner_vae.py configs/vae.json --dataset faces_only``` | demo r√°pida |
| OpenMoji completo | ```python src/runner_vae.py configs/vae.json --dataset emoji_full --max_emojis 2000``` | ~4 200 PNG |
| dSprites 64√ó64 | ```python src/runner_vae.py configs/vae.json --dataset dsprites --beta_final 4 --kl_ramp_epochs 100``` | muestra disentanglement |

Cada run guarda en  
checkpoints/`<dataset>`_img`<size>`_beta`<Œ≤>`_`<timestamp>`/  
    vae_weights.npz ¬∑ loss_history.npy ¬∑ vae_generated.png  

Un *sample raw* del dataset queda en  
data/sample_`<dataset>`.png

---

## üìÅ Estructura de carpetas

src/              ¬∑ implementaci√≥n AE / VAE / trainer  
configs/          ¬∑ JSON de hiper-par√°metros  
data/             ¬∑ datasets y samples de referencia  
checkpoints/      ¬∑ pesos + salidas organizadas por experimento  
docs/             ¬∑ enunciado y apuntes √∫tiles  

---

## üìä An√°lisis de resultados  *(pendiente)*

Se agregar√°n:  
‚Ä¢ gr√°ficas de convergencia,  
‚Ä¢ proyecci√≥n 2-D del espacio latente (AE) y  
‚Ä¢ interpolaciones en el VAE con distintas Œ≤.