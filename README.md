# TP 5 ‚Äì SIA ¬∑ Deep Learning  
*Autoencoders, Denoising AE y Variational AE*

> **Sistemas de Inteligencia Artificial**  
> ITBA ‚Äì 2025  

[üìë Enunciado oficial](docs/sia-tp5.pdf)

---

## Introducci√≥n

Este TP explora tres variantes de autoencoders sobre distintos datasets:

* **AE b√°sico** ‚Äì aprende los 32 caracteres 5 √ó 7 de `font.h`  
* **Denoising AE** ‚Äì quita ruido binario de los mismos caracteres  
* **VAE** ‚Äì genera emojis (OpenMoji), disentangled sprites (dSprites) y caras (LFW deepfunneled)

---

## ‚öôÔ∏è Instalaci√≥n r√°pida

1. Clonar el repositorio  
   ```git clone https://github.com/tu-usuario/sia-tp5.git```
2. Crear y activar entorno virtual  
   ```python -m venv venv && source venv/bin/activate```
3. Instalar dependencias  
   ```pip install -r requirements.txt```

---

## ‚ñ∂Ô∏è Ejecuci√≥n

### Ejercicio 1a ‚Äî Autoencoder b√°sico (font.h)
1. Para encontrar la arquitectura √≥ptima, se debe correr:
   ```bash
   python src/ex1/part_a/ej_b.py configs/ex1/config_a_1.json
   ```
   Donde el archivo de configuraci√≥n contiene distintos experimentos y el directorio de font.h
   En el directorio `/experimentos` se guardar√° el gr√°fico de p√©rdida por √©poca y un archivo json con los resultados finales de cada experimento.

2. Para graficar el espacio latente, se debe correr:
   ```bash 
   python src/ex1/part_a/ej_c.py
   ```
   Tomar√° directamente el archivo font.h y la configuraci√≥n `configs/ex1/optimal.json` donde se encuentran los detalles de la arquitectura √≥ptima hallada en el item anterior.
   Genera un gr√°fico del espacio latente 2D con los caracteres proyectados sobre el punto (z) que los codifica.

3. Para generar nuevas letras que no pertenecen al conjunto de entrenamiento, se debe correr:
   ```bash
   python src/ex1/part_a/ej_d.py
   ```
   Entrena al autoencoder con las configuraciones √≥ptimas de `configs/ex1/optimal.json`, luego se realizan tres gr√°ficos: primero se divide el espacio latente en 25 bloques (5x5), cada uno con un punto central (x,y). Se usa este punto (x,y) como entrada del decodificador, generando un caracter para este punto. Se genera un gr√°fico con los 25 caracteres generados. Se repite el proceso para 10x10 y 20x20.

---

### Ejercicio 1b ‚Äî Denoising Autoencoder
Para distorsionar las entradas y estudiar la capacidad del Autoencoder de eliminar el ruido, se debe correr:
```bash
python src/analisis_dae.py configs/ex1/optimal.json data/font.h
```
En la configuraci√≥n se especifica la arquitectura √≥ptima y el nivel de ruido para la prueba.
Se har√°n 5 ejecuciones de esta prueba de denoising.
Se generar√°n tres archivos en `/checkpoints`
* `dae_loss_avg_plot.png` con la p√©rdida promedio a lo largo de las √©pocas en las 5 ejecuciones
* `ejemplo_mejor.png` y `ejemplo_peor.png` con una visualizaci√≥n de la entrada con ruido, la reconstrucci√≥n del AE y la entrada original para el caracter con menos bits de error en promedio, y el caracter con m√°s bits de error en promedio.

---

### Ejercicio 2 ‚Äî Variational AE

Runner  `src/runner_vae.py`  
**Flags clave**  
‚Ä¢ `--dataset`‚ÄÉfaces_only | emoji_full | dsprites | faces_lfw  
‚Ä¢ `--img_size`‚ÄÉ28 / 32 / 64 (se ajusta solo para dsprites / ffhq / lfw)  
‚Ä¢ `--beta_final`‚ÄÉvalor final de Œ≤  
‚Ä¢ `--kl_ramp_epochs`‚ÄÉ√©pocas para annealing 0 ‚Üí Œ≤  
‚Ä¢ `--max_emojis`‚ÄÉm√°x. de im√°genes a usar  
‚Ä¢ `--refresh_dataset`‚ÄÉre-descarga forzada (OpenMoji)

**Comandos sugeridos**

| Dataset | Comando | Comentario |
|---------|---------|------------|
| Caras amarillas (197√ó32 px) | ```python src/runner_vae.py configs/vae_optimized.json --dataset faces_only``` | demo r√°pida |
| OpenMoji completo (‚âà 4 200) | ```python src/runner_vae.py configs/vae_optimized.json --dataset emoji_full --max_emojis 2000``` | m√°s diversidad |
| dSprites 64√ó64 | ```python src/runner_vae.py configs/vae_optimized.json --dataset dsprites --beta_final 4 --kl_ramp_epochs 100``` | prueba disentanglement |
| LFW deepfunneled (8 000) | ```python src/runner_vae.py configs/vae_optimized.json --dataset faces_lfw --max_emojis 8000 --img_size 64``` | descarga via TF-Datasets |

Cada ejecuci√≥n crea  
`checkpoints/<dataset>_img<size>_beta<Œ≤>_<timestamp>/`  
‚ÄÉ¬∑ vae_weights.npz‚ÄÉ¬∑ loss_history.npy‚ÄÉ¬∑ vae_generated.png  

Adem√°s se guarda un *sample* del dataset en  
`data/sample_<dataset>.png`

## üìÅ Estructura de carpetas

src/              ¬∑ implementaci√≥n AE / VAE / trainer  
configs/          ¬∑ JSON de hiper-par√°metros  
data/             ¬∑ datasets y samples de referencia  
checkpoints/      ¬∑ pesos + salidas organizadas por experimento  
docs/             ¬∑ enunciado y apuntes √∫tiles  